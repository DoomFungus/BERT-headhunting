{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34e1685b8c6c4de4be7aeff214dd80dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a45ffcb9e77428d88b87c898fa2e865",
              "IPY_MODEL_775103cb00b048749d5a58778474eff6",
              "IPY_MODEL_0f16c6dbb83a464d8bbc465edd3ddd50"
            ],
            "layout": "IPY_MODEL_a9a80a1f88ba4e16a3997cf2d344980e"
          }
        },
        "5a45ffcb9e77428d88b87c898fa2e865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce536f3d61345ce851657d01c322156",
            "placeholder": "​",
            "style": "IPY_MODEL_667c4ddb76d44a48887d65eaf959b7c2",
            "value": "Map: 100%"
          }
        },
        "775103cb00b048749d5a58778474eff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e289f38928fa43bfbfa1079299df1a9c",
            "max": 959,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d5b7452db5540b697f7c4702d0ec313",
            "value": 959
          }
        },
        "0f16c6dbb83a464d8bbc465edd3ddd50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86698e9156004b40815303927545e33c",
            "placeholder": "​",
            "style": "IPY_MODEL_5cae1e23167f45e38874b3af158455d5",
            "value": " 959/959 [00:00&lt;00:00, 2141.44 examples/s]"
          }
        },
        "a9a80a1f88ba4e16a3997cf2d344980e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce536f3d61345ce851657d01c322156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667c4ddb76d44a48887d65eaf959b7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e289f38928fa43bfbfa1079299df1a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5b7452db5540b697f7c4702d0ec313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86698e9156004b40815303927545e33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cae1e23167f45e38874b3af158455d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Masking and pruning BERT heads\n",
        "### By Pavlo Kravets\n",
        "\n",
        "As my project for a Deep Learning course, I decided to recreate the famous experiment: removing the heads of fine-tuned BERT model and testing how much the performance will be impacted.\n",
        "\n",
        "The original paper, \"Are Sixteen Heads Really Better than One?\" by Michel et al. can be found [here](https://arxiv.org/abs/1905.10650).\n",
        "\n",
        "I used the Transformers library by Huggingface (basing it on PyTorch). A lot of this work is based on their [experimental setup](https://github.com/huggingface/transformers/blob/main/examples/research_projects/bertology/run_bertology.py). Sadly (or luckily, because I got to do something interesting), it does not seem to work with the current Transformers version, so I had to rework it a bit."
      ],
      "metadata": {
        "id": "EMouG13V1mve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivA2X-0lMN6a",
        "outputId": "caba2d80-38f5-4104-d5ca-56359e93519c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and model\n",
        "\n",
        "I will be using bert-base-uncased as my model of choice and will perform the evaluation against CoLA task. Given that it is a benchmark task, and the test labels are unavailable, I had to create new dataset to use. I united the train and validation splits, and the split the result into three parts: train, validation, and test. As such, the obtained results cannot be directly compared to the benchmark, as a task is a bit different."
      ],
      "metadata": {
        "id": "Mlqph18j3pwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed\n",
        ")\n",
        "from datasets import (\n",
        "    load_dataset,\n",
        "    DatasetDict\n",
        ")\n",
        "from functools import partial\n",
        "from evaluate import (\n",
        "    load,\n",
        "    evaluator\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "def create_raw_dataset():\n",
        "  raw_dataset = {}\n",
        "  raw_dataset['train'] = load_dataset('glue', 'cola', split = 'train[0%:80%]+validation[0%:85%]')\n",
        "  raw_dataset['validation'] = load_dataset('glue', 'cola', split = 'train[80%:90%]+validation[85%:95%]')\n",
        "  raw_dataset['test'] = load_dataset('glue', 'cola', split = 'train[90%:100%]+validation[95%:100%]')\n",
        "  return DatasetDict(raw_dataset)\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "  return tokenizer(dataset['sentence'], truncation=True)\n",
        "\n",
        "def compute_metrics(eval_pred, metric):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "raw_dataset = create_raw_dataset()\n",
        "\n",
        "num_labels = len(raw_dataset['train'].unique('label'))\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels =  num_labels)\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokenized_dataset = raw_dataset.map(partial(tokenize_dataset, tokenizer = tokenizer))\n",
        "\n",
        "cola_metric = load('glue', 'cola')\n",
        "\n",
        "training_args = TrainingArguments('model_bert-base-uncased')\n",
        "trainer = Trainer(base_model,\n",
        "                  training_args,\n",
        "                  train_dataset = tokenized_dataset['train'],\n",
        "                  eval_dataset = tokenized_dataset['validation'],\n",
        "                  tokenizer = tokenizer,\n",
        "                  compute_metrics=partial(compute_metrics, metric = cola_metric))\n",
        "trainer.train()\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "cvev47PqF1pH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "34e1685b8c6c4de4be7aeff214dd80dc",
            "5a45ffcb9e77428d88b87c898fa2e865",
            "775103cb00b048749d5a58778474eff6",
            "0f16c6dbb83a464d8bbc465edd3ddd50",
            "a9a80a1f88ba4e16a3997cf2d344980e",
            "4ce536f3d61345ce851657d01c322156",
            "667c4ddb76d44a48887d65eaf959b7c2",
            "e289f38928fa43bfbfa1079299df1a9c",
            "7d5b7452db5540b697f7c4702d0ec313",
            "86698e9156004b40815303927545e33c",
            "5cae1e23167f45e38874b3af158455d5"
          ]
        },
        "outputId": "9dcf0a42-8dcb-4183-98db-c4920603750d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/959 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34e1685b8c6c4de4be7aeff214dd80dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2898' max='2898' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2898/2898 04:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.547700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.471300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.313000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.183900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will move the model to evaluation mode (disabling the dropout) and perform the initial evaluation. CoLA uses Matthews correlation coefficient as it's metric"
      ],
      "metadata": {
        "id": "uA0Z2f8T5E7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.eval()\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "evaluation_res = task_evaluator.compute(\n",
        "          model_or_pipeline=base_model,\n",
        "          data=raw_dataset['test'],\n",
        "          input_column='sentence',\n",
        "          metric=cola_metric,\n",
        "          tokenizer = tokenizer,\n",
        "          label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1})\n",
        "{'matthews_correlation': evaluation_res['matthews_correlation'],\n",
        "        'inference_time': 1/evaluation_res['samples_per_second'],\n",
        "        'memory_footprint': base_model.get_memory_footprint()}"
      ],
      "metadata": {
        "id": "eMYVSPU-NJMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56954fb2-e5f8-474f-ae18-f9905b5dd1f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matthews_correlation': 0.5612113773304545,\n",
              " 'inference_time': 0.026073023803748516,\n",
              " 'memory_footprint': 437943304}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "def cola_compute_metrics(preds, labels):\n",
        "  return matthews_corrcoef(labels, preds)\n",
        "\n",
        "pruning_dataset = tokenized_dataset['test'].remove_columns('sentence').with_format(\"torch\")\n",
        "\n",
        "eval_dataloader = DataLoader(pruning_dataset, batch_size = 1)"
      ],
      "metadata": {
        "id": "Q2FZVTRP2gFU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to compute the head importance. We do it by obtaining the gradients for all attention heads. Then we normalize them - layerwise and globally. We also obtain predictions for the given data - we are using them to calculate model's score on given metric.\n"
      ],
      "metadata": {
        "id": "6blvMBto7Wxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "def compute_heads_importance(model, eval_dataloader,\n",
        "                             compute_importance=True,\n",
        "                             head_mask=None,\n",
        "                             actually_pruned=False,\n",
        "                             print_iteration=True):\n",
        "  # Prepare our tensors\n",
        "  n_layers, n_heads = model.config.num_hidden_layers, model.config.num_attention_heads\n",
        "  head_importance = torch.zeros(n_layers, n_heads).to(device)\n",
        "\n",
        "  if head_mask is None:\n",
        "    head_mask = torch.ones(n_layers, n_heads).to(device)\n",
        "\n",
        "  head_mask.requires_grad_(requires_grad=True)\n",
        "  # If actually pruned attention multi-head, set head mask to None to avoid shape mismatch\n",
        "  if actually_pruned:\n",
        "    head_mask = None\n",
        "\n",
        "  preds = None\n",
        "  labels = None\n",
        "  tot_tokens = 0.0\n",
        "\n",
        "  for step, inputs in enumerate(tqdm(eval_dataloader, desc=\"Iteration\", disable = not print_iteration)):\n",
        "    for k, v in inputs.items():\n",
        "      inputs[k] = v.to(device)\n",
        "\n",
        "    # Do a forward pass (not with torch.no_grad() since we need gradients for importance score - see below)\n",
        "    outputs = model.forward(input_ids = inputs['input_ids'],\n",
        "                    token_type_ids = inputs['token_type_ids'],\n",
        "                    attention_mask = inputs['attention_mask'],\n",
        "                    labels = inputs['label'],\n",
        "                    output_attentions = True,\n",
        "                    head_mask=head_mask)\n",
        "    loss, logits, all_attentions = (\n",
        "            outputs['loss'],\n",
        "            outputs['logits'],\n",
        "            outputs['attentions'],\n",
        "    )  # Loss and logits are the first, attention the last\n",
        "    loss.backward()  # Backpropagate to populate the gradients in the head mask\n",
        "\n",
        "    if compute_importance:\n",
        "      head_importance += head_mask.grad.abs().detach()\n",
        "\n",
        "    # Also store our logits/labels if we want to compute metrics afterwards\n",
        "    if preds is None:\n",
        "      preds = logits.detach().cpu().numpy()\n",
        "      labels = inputs[\"label\"].detach().cpu().numpy()\n",
        "    else:\n",
        "      preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "      labels = np.append(labels, inputs[\"label\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    tot_tokens += inputs[\"attention_mask\"].float().detach().sum().data\n",
        "\n",
        "  # Normalize\n",
        "  head_importance /= tot_tokens\n",
        "  # Layerwise importance normalization\n",
        "\n",
        "  exponent = 2\n",
        "  norm_by_layer = torch.pow(torch.pow(head_importance, exponent).sum(-1), 1 / exponent)\n",
        "  head_importance /= norm_by_layer.unsqueeze(-1) + 1e-20\n",
        "\n",
        "  head_importance = (head_importance - head_importance.min()) / (head_importance.max() - head_importance.min())\n",
        "\n",
        "  return head_importance, preds, labels"
      ],
      "metadata": {
        "id": "GzCBvFE2ZfG8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method is used to iteratively mask the heads of the model until it reaches the threshold. It does so in batches:\n",
        "1. First, the mask is calculated for the original model\n",
        "2. Then, several (up to head batch size) least important unmasked heads are chosen and masked\n",
        "3. Then, the model is scored via the given metric\n",
        "4. If the threshold is not yet reached, steps 2-4 are repeated\n",
        "In this case, the batch size is 0.1 of the number of heads (144 for BERT) and the threshold is 0.75 of the original score"
      ],
      "metadata": {
        "collapsed": false,
        "id": "tz3Qc-C48IIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_heads(model, eval_dataloader):\n",
        "  head_importance, preds, labels = compute_heads_importance(model, eval_dataloader, print_iteration = False)\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  original_score = cola_compute_metrics(preds, labels)\n",
        "  print(f\"Masking: original score: {original_score}, threshold: {original_score * 0.75}\")\n",
        "\n",
        "  new_head_mask = torch.ones_like(head_importance)\n",
        "  num_to_mask = max(1, int(new_head_mask.numel() * 0.1))\n",
        "\n",
        "  current_score = original_score\n",
        "  masking_results = {'scores': [original_score], 'heads': [new_head_mask.numel()]}\n",
        "  while current_score >= original_score * 0.75:\n",
        "    head_mask = new_head_mask.clone()\n",
        "    head_importance[head_mask == 0.0] = float(\"Inf\")\n",
        "    current_heads_to_mask = head_importance.view(-1).sort()[1]\n",
        "\n",
        "    if len(current_heads_to_mask) <= num_to_mask:\n",
        "      break\n",
        "\n",
        "    # mask heads\n",
        "    current_heads_to_mask = current_heads_to_mask[:num_to_mask]\n",
        "    new_head_mask = new_head_mask.view(-1)\n",
        "    with torch.no_grad():\n",
        "      new_head_mask[current_heads_to_mask] = 0.0\n",
        "    new_head_mask = new_head_mask.view_as(head_mask)\n",
        "    new_head_mask = new_head_mask.clone().detach()\n",
        "\n",
        "    # Compute metric and head importance again\n",
        "    head_importance, preds, labels = compute_heads_importance(model, eval_dataloader, head_mask=new_head_mask)\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    current_score = cola_compute_metrics(preds, labels)\n",
        "    masking_results['scores'].append(current_score)\n",
        "    masking_results['heads'].append(new_head_mask.sum().item())\n",
        "    print(f\"Masking: current score: {current_score}, \\\n",
        "    remaining heads {new_head_mask.sum()} \\\n",
        "    ({new_head_mask.sum() / new_head_mask.numel() * 100} percents)\")\n",
        "\n",
        "  return head_mask, masking_results"
      ],
      "metadata": {
        "id": "U3Wg8uyk5fuH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, this function prunes the attention heads. Unlike masking, it actually removes the heads of the model, making it smaller. It can also increase the inference speed - but the common belief is that the effect is not particularly pronounced on the stronger hardware, as the layer cannot be fully masked."
      ],
      "metadata": {
        "collapsed": false,
        "id": "D9oPGyws8III"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_heads(model, eval_dataloader, head_mask):\n",
        "  _, preds, labels = compute_heads_importance(model, eval_dataloader, compute_importance=False, head_mask=head_mask, print_iteration = False)\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "\n",
        "  original_num_params = sum(p.numel() for p in model.parameters())\n",
        "  heads_to_prune = {layer: (1 - head_mask[layer].long()).nonzero().squeeze().tolist() for layer in range(len(head_mask))}\n",
        "\n",
        "  assert sum(len(h) for h in heads_to_prune.values()) == (1 - head_mask.long()).sum().item()\n",
        "  model.prune_heads(heads_to_prune)\n",
        "  pruned_num_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "  _, preds, labels = compute_heads_importance(\n",
        "        model,\n",
        "        eval_dataloader,\n",
        "        compute_importance=False,\n",
        "        head_mask=None,\n",
        "        actually_pruned=True,\n",
        "        print_iteration = False\n",
        "        )\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  score_pruning = cola_compute_metrics(preds, labels)\n",
        "\n",
        "  print(\n",
        "      f\"\\nPruning: original num of params: {original_num_params}, \\\n",
        "      after pruning {pruned_num_params} \\\n",
        "      ({pruned_num_params / original_num_params * 100} percents)\",\n",
        "\n",
        "  )\n",
        "  print(f\"Score with pruning: {score_pruning}\")"
      ],
      "metadata": {
        "id": "CEUjMR095imn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_head_mask, masking_results = mask_heads(base_model, eval_dataloader)\n",
        "prune_heads(base_model, eval_dataloader, result_head_mask)"
      ],
      "metadata": {
        "id": "GKGma_rLBAMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ec76a6-6739-44c5-9524-10c31387a90a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: original score: 0.5612113773304545, threshold: 0.4209085329978408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:30<00:00, 29.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.5557079855375493,     remaining heads 130.0     (90.27777862548828 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:31<00:00, 29.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.5455098635779807,     remaining heads 116.0     (80.55555725097656 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:31<00:00, 28.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.5345652751944655,     remaining heads 102.0     (70.83332824707031 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:31<00:00, 29.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.524822946686575,     remaining heads 88.0     (61.11111068725586 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:31<00:00, 28.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.5021452329480853,     remaining heads 74.0     (51.38888931274414 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:31<00:00, 29.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.46637167477893554,     remaining heads 60.0     (41.666664123535156 percents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 907/907 [00:30<00:00, 29.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masking: current score: 0.39568183177840416,     remaining heads 46.0     (31.94444465637207 percents)\n",
            "\n",
            "Pruning: original num of params: 109483778,       after pruning 92952578       (84.90077680731844 percents)\n",
            "Score with pruning: 0.46637167477893554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly enough, we can see that on the used hardware (T4 GPU in Google Colab) the inference speed up is reasonably high - the inference speed is lower by 20%, from ~0.025 to ~0.02, while the size of the model has shrunk by ~17%. The relatively small memory footprint decrease can be attributed to non-attention layers of the model - even if we pruned 84 out of 144 heads, there are a lot of other parameters in the model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "tAY0QPwW8IIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_res = task_evaluator.compute(\n",
        "          model_or_pipeline=base_model,\n",
        "          data=raw_dataset['test'],\n",
        "          input_column='sentence',\n",
        "          metric=cola_metric,\n",
        "          tokenizer = tokenizer,\n",
        "          label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1})\n",
        "{'matthews_correlation': evaluation_res['matthews_correlation'],\n",
        "        'inference_time': 1/evaluation_res['samples_per_second'],\n",
        "        'memory_footprint': base_model.get_memory_footprint()}"
      ],
      "metadata": {
        "id": "gkcmr2j0vKyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd77ef74-d418-4de7-9e0c-0d94f336df77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matthews_correlation': 0.46637167477893554,\n",
              " 'inference_time': 0.012441920599779513,\n",
              " 'memory_footprint': 371818504}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the plot of the drop in the score against the number of remaining heads. As we can see, several of the least important heads can be removed almost without the drop in the score. The effect may be even more pronounced with smaller batch size."
      ],
      "metadata": {
        "collapsed": false,
        "id": "0BNHu63g8IIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(masking_results['heads'], masking_results['scores'])\n",
        "plt.xlabel(\"Number of attention heads\")\n",
        "plt.ylabel(\"CoLA score\")\n",
        "plt.axis([max(masking_results['heads'])+1, min(masking_results['heads'])-1, 0, max(masking_results['scores'])+0.1])\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "PgSEtIc7wPgi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "7a44519b-a524-4f4e-9f5c-cd62e8e5a962"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional thoughts\n",
        "\n",
        "While the technique introduced by Michel et al. certainly has a lot of merits, this particular implementation of it may fail to generalize. Given that we prune heads and score the model using the same dataset split, the model may just \"forget\" the patterns not present in it.\n",
        "\n",
        "Secondly, even the important heads may be further improved upon. Combining pruning with another approach, such as distillation, may give even better results."
      ],
      "metadata": {
        "collapsed": false,
        "id": "A2nmYoSw8IIL"
      }
    }
  ]
}